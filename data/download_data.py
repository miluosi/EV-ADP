import numpy as np
import pandas as pd
import os
import requests
import pandas as pd
from pathlib import Path
import time



def download_data(year,month,typedata):
    if typedata == 'nyc':
        str_ym = str(year) + '-' + str(month).zfill(2)
        yellow_taxi_url = "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_" + str_ym + ".parquet"
        print(f"ğŸ“¥ çœŸå®æ•°æ®ä¸‹è½½é“¾æ¥: {yellow_taxi_url}")
        data_folder = Path("data/parquet")
        targetf1 = "yellow_tripdata_"+ str_ym + ".parquet"
        target_file = data_folder / targetf1

        print("ğŸ“¥ å‡†å¤‡ä¸‹è½½NYC Yellow TaxiçœŸå®æ•°æ®...")
        print("=" * 60)
        print(f"ğŸ”— æ•°æ®æºURL: {yellow_taxi_url}")
        print(f"ğŸ’¾ ä¿å­˜è·¯å¾„: {target_file}")

        if target_file.exists():
            file_size = target_file.stat().st_size / (1024 * 1024)
            print(f"âœ… æ–‡ä»¶å·²å­˜åœ¨: {target_file.name} ({file_size:.1f} MB)")
            print("è·³è¿‡ä¸‹è½½...")
        else:
            print("ğŸš€ å¼€å§‹ä¸‹è½½... (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´)")
            
            try:
                # ä½¿ç”¨æµå¼ä¸‹è½½ä»¥å¤„ç†å¤§æ–‡ä»¶
                response = requests.get(yellow_taxi_url, stream=True)
                response.raise_for_status()
                
                # è·å–æ–‡ä»¶å¤§å°
                total_size = int(response.headers.get('content-length', 0))
                total_size_mb = total_size / (1024 * 1024)
                print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {total_size_mb:.1f} MB")
                
                # ç¡®ä¿dataæ–‡ä»¶å¤¹å­˜åœ¨
                data_folder.mkdir(exist_ok=True)
                
                # ä¸‹è½½æ–‡ä»¶
                downloaded = 0
                start_time = time.time()
                
                with open(target_file, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            
                            # æ¯10MBæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                            if downloaded % (10 * 1024 * 1024) == 0 or downloaded == total_size:
                                progress = (downloaded / total_size) * 100 if total_size > 0 else 0
                                elapsed = time.time() - start_time
                                speed = downloaded / (1024 * 1024) / elapsed if elapsed > 0 else 0
                                print(f"â¬‡ï¸  è¿›åº¦: {progress:.1f}% ({downloaded/(1024*1024):.1f}/{total_size_mb:.1f} MB) "
                                    f"é€Ÿåº¦: {speed:.1f} MB/s")
                
                elapsed = time.time() - start_time
                print(f"âœ… ä¸‹è½½å®Œæˆ! ç”¨æ—¶: {elapsed:.1f}ç§’")
                
                # éªŒè¯æ–‡ä»¶
                if target_file.exists():
                    file_size = target_file.stat().st_size / (1024 * 1024)
                    print(f"âœ… æ–‡ä»¶éªŒè¯æˆåŠŸ: {file_size:.1f} MB")
                else:
                    print("âŒ æ–‡ä»¶ä¸‹è½½å¤±è´¥")
                    
            except requests.exceptions.RequestException as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
                print("ğŸ’¡ ä½ å¯èƒ½éœ€è¦:")
                print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
                print("   2. æˆ–æ‰‹åŠ¨ä»ä»¥ä¸‹URLä¸‹è½½æ–‡ä»¶:")
                print(f"      {yellow_taxi_url}")
                print(f"   3. ç„¶åä¿å­˜åˆ°: {target_file}")
            except Exception as e:
                print(f"âŒ æ„å¤–é”™è¯¯: {e}")
    else:
        print("âŒ åªæ”¯æŒä¸‹è½½NYC Yellow Taxiæ•°æ®ã€‚è¯·æ£€æŸ¥è¾“å…¥å‚æ•°ã€‚")
        print("ğŸ’¡ å¯ç”¨é€‰é¡¹: 'nyc'")
        print("ğŸ“„ ç¤ºä¾‹: download_data(2023, 10, 'nyc')")


def describedata(year, month, typedata):
    if typedata == 'nyc':
        str_ym = str(year) + '-' + str(month).zfill(2)
        data_file = Path("data/parquet/yellow_tripdata_" + str_ym + ".parquet")

        try:
            # è¯»å–parquetæ–‡ä»¶
            print(f"ğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶: {data_file.name}")
            df_real = pd.read_parquet(data_file)
            
            print(f"âœ… æ•°æ®è¯»å–æˆåŠŸ!")
            print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {df_real.shape[0]:,} è¡Œ Ã— {df_real.shape[1]} åˆ—")
            
            # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            print(f"\nğŸ” æ•°æ®åˆ—ä¿¡æ¯:")
            print("-" * 40)
            for i, col in enumerate(df_real.columns, 1):
                dtype = str(df_real[col].dtype)
                non_null = df_real[col].count()
                null_pct = (1 - non_null/len(df_real)) * 100
                print(f"{i:2d}. {col:<25} {dtype:<15} éç©º: {non_null:>8,} ({100-null_pct:.1f}%)")
            
            # æ˜¾ç¤ºæ•°æ®æ ·æœ¬
            print(f"\nğŸ“‹ æ•°æ®å‰5è¡Œ:")
            print("-" * 40)
            display_cols = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 
                        'PULocationID', 'DOLocationID', 'passenger_count', 
                        'trip_distance', 'fare_amount']
            
            available_cols = [col for col in display_cols if col in df_real.columns]
            print(df_real[available_cols].head())
            
            # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“ˆ å…³é”®å­—æ®µç»Ÿè®¡:")
            print("-" * 40)
            
            if 'trip_distance' in df_real.columns:
                print(f"è¡Œç¨‹è·ç¦»:")
                print(f"  å¹³å‡: {df_real['trip_distance'].mean():.2f} è‹±é‡Œ")
                print(f"  ä¸­ä½æ•°: {df_real['trip_distance'].median():.2f} è‹±é‡Œ")
                print(f"  èŒƒå›´: {df_real['trip_distance'].min():.2f} - {df_real['trip_distance'].max():.2f} è‹±é‡Œ")
            
            if 'fare_amount' in df_real.columns:
                print(f"è½¦è´¹:")
                print(f"  å¹³å‡: ${df_real['fare_amount'].mean():.2f}")
                print(f"  ä¸­ä½æ•°: ${df_real['fare_amount'].median():.2f}")
                print(f"  èŒƒå›´: ${df_real['fare_amount'].min():.2f} - ${df_real['fare_amount'].max():.2f}")
            
            if 'passenger_count' in df_real.columns:
                print(f"ä¹˜å®¢æ•°:")
                passenger_counts = df_real['passenger_count'].value_counts().sort_index()
                print(f"  åˆ†å¸ƒ: {dict(passenger_counts.head())}")
            
            # ä½ç½®IDç»Ÿè®¡
            if 'PULocationID' in df_real.columns and 'DOLocationID' in df_real.columns:
                unique_pickup = df_real['PULocationID'].nunique()
                unique_dropoff = df_real['DOLocationID'].nunique()
                print(f"ä½ç½®åŒºåŸŸ:")
                print(f"  ä¸Šè½¦åŒºåŸŸæ•°: {unique_pickup}")
                print(f"  ä¸‹è½¦åŒºåŸŸæ•°: {unique_dropoff}")
                print(f"  æœ€çƒ­é—¨ä¸Šè½¦åŒºåŸŸ: {df_real['PULocationID'].mode().iloc[0]} (ID)")
                print(f"  æœ€çƒ­é—¨ä¸‹è½¦åŒºåŸŸ: {df_real['DOLocationID'].mode().iloc[0]} (ID)")
            
            # æ—¶é—´åˆ†æ
            if 'tpep_pickup_datetime' in df_real.columns:
                df_real['pickup_hour'] = pd.to_datetime(df_real['tpep_pickup_datetime']).dt.hour
                df_real['pickup_day'] = pd.to_datetime(df_real['tpep_pickup_datetime']).dt.day
                
                print(f"æ—¶é—´åˆ†æ:")
                print(f"  æ•°æ®æ—¶é—´èŒƒå›´: {df_real['tpep_pickup_datetime'].min()} è‡³ {df_real['tpep_pickup_datetime'].max()}")
                print(f"  æœ€ç¹å¿™å°æ—¶: {df_real['pickup_hour'].mode().iloc[0]}ç‚¹")
                
                hourly_counts = df_real['pickup_hour'].value_counts().sort_index()
                print(f"  å°æ—¶åˆ†å¸ƒ (å‰5): {dict(hourly_counts.head())}")
            
            print(f"\nğŸ’¾ å˜é‡å: df_real (åŒ…å« {len(df_real):,} æ¡çœŸå®å‡ºç§Ÿè½¦è®°å½•)")
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {data_file.name}ã€‚è¯·å…ˆä¸‹è½½æ•°æ®ã€‚")
    else:
        print("âŒ åªæ”¯æŒæè¿°NYC Yellow Taxiæ•°æ®ã€‚è¯·æ£€æŸ¥è¾“å…¥å‚æ•°ã€‚")
        print("ğŸ’¡ å¯ç”¨é€‰é¡¹: 'nyc'")
        print("ğŸ“„ ç¤ºä¾‹: describedata(2023, 10, 'nyc')")


def cleandata(year,month,typedata):
    if typedata == 'nyc':
        str_ym = str(year) + '-' + str(month).zfill(2)
        data_file = Path("data/parquet/yellow_tripdata_" + str_ym + ".parquet")
        try:
            
            df_real = pd.read_parquet(data_file)
            df = df_real.copy()
            original_count = len(df)
            df = df[df['trip_distance'] > 0]  # è¡Œç¨‹è·ç¦»å¤§äº0
            df = df[df['fare_amount'] > 0]    # è½¦è´¹å¤§äº0
            df = df[df['PULocationID'] != df['DOLocationID']]  # ä¸Šä¸‹è½¦ä¸åŒåœ°ç‚¹
            df = df[df['PULocationID'].notna() & df['DOLocationID'].notna()]  # ä½ç½®IDä¸ä¸ºç©º
            
            # ç§»é™¤æç«¯å¼‚å¸¸å€¼
            df = df[df['trip_distance'] <= 50]  # è¡Œç¨‹è·ç¦»å°äº50è‹±é‡Œ
            df = df[df['fare_amount'] <= 500]   # è½¦è´¹å°äº500ç¾å…ƒ
            
            cleaned_count = len(df)
            removed_count = original_count - cleaned_count
            removed_pct = (removed_count / original_count) * 100
            
            print(f"   âœ… æ¸…æ´—å®Œæˆ: ç§»é™¤ {removed_count:,} æ¡å¼‚å¸¸è®°å½• ({removed_pct:.1f}%)")
            print(f"   ğŸ“Š æ¸…æ´—åæ•°æ®: {cleaned_count:,} æ¡è®°å½•")
            
            # 2. æå–æ—¶é—´ç‰¹å¾
            print(f"\nğŸ“… æå–æ—¶é—´ç‰¹å¾...")
            
            # è½¬æ¢æ—¶é—´æ ¼å¼
            df['pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])
            df['dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])
            
            # æå–æ—¶é—´ç‰¹å¾
            df['pickup_date'] = df['pickup_datetime'].dt.date
            df['pickup_hour'] = df['pickup_datetime'].dt.hour
            df['pickup_day_of_week'] = df['pickup_datetime'].dt.day_of_week  # 0=Monday, 6=Sunday
            df['pickup_day_name'] = df['pickup_datetime'].dt.day_name()
            
            # åˆ¤æ–­å·¥ä½œæ—¥/å‘¨æœ«
            df['is_weekend'] = df['pickup_day_of_week'].isin([5, 6])  # Saturday=5, Sunday=6
            df['day_type'] = df['is_weekend'].map({True: 'Weekend', False: 'Weekday'})
            
            # 3. æ•°æ®ç»Ÿè®¡
            print(f"   âœ… æ—¶é—´ç‰¹å¾æå–å®Œæˆ")
            
            # æ—¶é—´èŒƒå›´
            date_range = f"{df['pickup_date'].min()} è‡³ {df['pickup_date'].max()}"
            print(f"   ğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {date_range}")
            
            # å·¥ä½œæ—¥/å‘¨æœ«åˆ†å¸ƒ
            day_type_counts = df['day_type'].value_counts()
            print(f"   ğŸ“Š æ•°æ®åˆ†å¸ƒ:")
            for day_type, count in day_type_counts.items():
                pct = (count / len(df)) * 100
                print(f"      {day_type}: {count:,} æ¡è®°å½• ({pct:.1f}%)")
            
            # æ¯æ—¥è®°å½•æ•°ç»Ÿè®¡
            daily_counts = df.groupby('pickup_date').size()
            print(f"   ğŸ“ˆ æ¯æ—¥è®°å½•æ•°: å¹³å‡ {daily_counts.mean():.0f} æ¡ (èŒƒå›´: {daily_counts.min():,} - {daily_counts.max():,})")
            
            # å°æ—¶åˆ†å¸ƒ
            hourly_counts = df['pickup_hour'].value_counts().sort_index()
            peak_hour = hourly_counts.idxmax()
            print(f"   ğŸ• é«˜å³°å°æ—¶: {peak_hour}ç‚¹ ({hourly_counts[peak_hour]:,} æ¡è®°å½•)")
            
            # ä½ç½®ç»Ÿè®¡
            unique_locations = df[['PULocationID', 'DOLocationID']].stack().nunique()
            unique_od_pairs = len(df.groupby(['PULocationID', 'DOLocationID']))
            print(f"   ğŸ“ å”¯ä¸€ä½ç½®æ•°: {unique_locations}")
            print(f"   ğŸ”„ å”¯ä¸€ODå¯¹æ•°: {unique_od_pairs:,}")
            
            print(f"\nğŸ’¾ é¢„å¤„ç†å®Œæˆçš„æ•°æ®ä¿å­˜ä¸ºå˜é‡: df")
            print(f"ğŸ“Š æœ€ç»ˆæ•°æ®: {len(df):,} æ¡æ¸…æ´—åçš„å‡ºç§Ÿè½¦è®°å½•")
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {data_file.name}ã€‚è¯·å…ˆä¸‹è½½æ•°æ®ã€‚")
    else:
        print("âŒ åªæ”¯æŒæ¸…æ´—NYC Yellow Taxiæ•°æ®ã€‚è¯·æ£€æŸ¥è¾“å…¥å‚æ•°ã€‚")
        print("ğŸ’¡ å¯ç”¨é€‰é¡¹: 'nyc'")
        print("ğŸ“„ ç¤ºä¾‹: cleandata(2023, 10, 'nyc')")
    return df


def calculate_distance(lat_1, lon_1, lat_2, lon_2):
    """
    è®¡ç®—ä¸¤ä¸ªç»çº¬åº¦ä¹‹é—´çš„è·ç¦»ï¼ˆå•ä½ï¼šç±³ï¼‰
    ä½¿ç”¨Haversineå…¬å¼
    """
    from math import radians, sin, cos, sqrt, atan2

    R = 6371000  # åœ°çƒåŠå¾„ï¼Œå•ä½ä¸ºç±³
    phi_1 = radians(lat_1)
    phi_2 = radians(lat_2)
    delta_phi = radians(lat_2 - lat_1)
    delta_lambda = radians(lon_2 - lon_1)

    a = sin(delta_phi / 2) ** 2 + cos(phi_1) * cos(phi_2) * sin(delta_lambda / 2) ** 2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))

    return R * c/1000


def generatestaticdata(year,month,df):
    str_ym = str(year) + '-' + str(month).zfill(2)
    xlsx_weekday_file = Path("data/xlsx/static/yellow_sod_weekday_" + str_ym + ".xlsx")
    xlsx_weekend_file = Path("data/xlsx/static/yellow_sod_weekend_" + str_ym + ".xlsx")
    weekday_od_np_path = Path("data/npy/static/yellow_sod_weekday_" + str_ym + ".npy")
    weekend_od_np_path = Path("data/npy/static/yellow_sod_weekend_" + str_ym + ".npy") 


    # 1. ç”Ÿæˆå·¥ä½œæ—¥é™æ€ODæ•°æ®é›†
    print("ğŸ“ˆ ç”Ÿæˆå·¥ä½œæ—¥é™æ€ODæ•°æ®é›†...")
    print("=" * 60)

    # åªä½¿ç”¨2024å¹´1æœˆçš„æ•°æ®ç¡®ä¿æ•°æ®ä¸€è‡´æ€§
    df_main = df[df['pickup_datetime'].dt.year == year].copy()
    print(f"ğŸ“Š ä½¿ç”¨{year}å¹´æ•°æ®: {len(df_main):,} æ¡è®°å½•")

    # é‡æ–°è®¡ç®—å·¥ä½œæ—¥å’Œå‘¨æœ«çš„å¤©æ•°
    weekday_dates_main = df_main[df_main['day_type'] == 'Weekday']['pickup_date'].unique()
    weekend_dates_main = df_main[df_main['day_type'] == 'Weekend']['pickup_date'].unique()

    n_weekdays = len(weekday_dates_main)
    n_weekends = len(weekend_dates_main)

    print(f"ğŸ“… {year}å¹´æ•°æ®è¦†ç›–:")
    print(f"   å·¥ä½œæ—¥: {n_weekdays} å¤©")
    print(f"   å‘¨æœ«: {n_weekends} å¤©")

    # 1. é‡æ–°ç”Ÿæˆå·¥ä½œæ—¥é™æ€ODæ•°æ®é›†ï¼ˆå¹³å‡æ¯å¤©éœ€æ±‚ï¼‰
    print(f"\nğŸ“ˆ ç”Ÿæˆå·¥ä½œæ—¥é™æ€ODæ•°æ®é›†ï¼ˆå¹³å‡æ¯å¤©éœ€æ±‚ï¼‰...")
    weekday_data_main = df_main[df_main['day_type'] == 'Weekday'].copy()

    # æŒ‰ODå¯¹èšåˆå¹¶è®¡ç®—å¹³å‡æ¯å¤©éœ€æ±‚
    weekday_od_correct = weekday_data_main.groupby(['PULocationID', 'DOLocationID']).agg({
        'fare_amount': ['count', 'sum', 'mean'],
        'trip_distance': ['sum', 'mean'],
        'passenger_count': 'sum'
    }).round(3)

    # å±•å¹³åˆ—å
    weekday_od_correct.columns = ['total_trips', 'total_fare', 'avg_fare', 'total_distance', 'avg_distance', 'total_passengers']
    weekday_od_correct = weekday_od_correct.reset_index()

    # è®¡ç®—å¹³å‡æ¯å¤©éœ€æ±‚
    weekday_od_correct['daily_demand'] = (weekday_od_correct['total_trips'] / n_weekdays).round(2)
    weekday_od_correct['daily_fare'] = (weekday_od_correct['total_fare'] / n_weekdays).round(2)
    weekday_od_correct['daily_distance'] = (weekday_od_correct['total_distance'] / n_weekdays).round(2)
    weekday_od_correct['daily_passengers'] = (weekday_od_correct['total_passengers'] / n_weekdays).round(2)

    # æ·»åŠ æ ‡è¯†
    weekday_od_correct['day_type'] = 'Weekday'
    weekday_od_correct['n_days'] = n_weekdays

    print(f"   âœ… å·¥ä½œæ—¥ODå¯¹: {len(weekday_od_correct):,} å¯¹")
    print(f"   ğŸ“Š éœ€æ±‚ç»Ÿè®¡ (åŸºäº {n_weekdays} ä¸ªå·¥ä½œæ—¥):")
    print(f"      å¹³å‡æ¯å¤©æ€»éœ€æ±‚: {weekday_od_correct['daily_demand'].sum():.0f} è¡Œç¨‹/å¤©")
    print(f"      å¹³å‡ODå¯¹éœ€æ±‚: {weekday_od_correct['daily_demand'].mean():.2f} è¡Œç¨‹/å¤©")
    print(f"      æœ€é«˜å•ODæ—¥éœ€æ±‚: {weekday_od_correct['daily_demand'].max():.0f} è¡Œç¨‹/å¤©")

    # 2. é‡æ–°ç”Ÿæˆå‘¨æœ«é™æ€ODæ•°æ®é›†ï¼ˆå¹³å‡æ¯å¤©éœ€æ±‚ï¼‰
    print(f"\nğŸ“ˆ ç”Ÿæˆå‘¨æœ«é™æ€ODæ•°æ®é›†ï¼ˆå¹³å‡æ¯å¤©éœ€æ±‚ï¼‰...")
    weekend_data_main = df_main[df_main['day_type'] == 'Weekend'].copy()

    # æŒ‰ODå¯¹èšåˆå¹¶è®¡ç®—å¹³å‡æ¯å¤©éœ€æ±‚
    weekend_od_correct = weekend_data_main.groupby(['PULocationID', 'DOLocationID']).agg({
        'fare_amount': ['count', 'sum', 'mean'],
        'trip_distance': ['sum', 'mean'],
        'passenger_count': 'sum'
    }).round(3)

    # å±•å¹³åˆ—å
    weekend_od_correct.columns = ['total_trips', 'total_fare', 'avg_fare', 'total_distance', 'avg_distance', 'total_passengers']
    weekend_od_correct = weekend_od_correct.reset_index()

    # è®¡ç®—å¹³å‡æ¯å¤©éœ€æ±‚
    weekend_od_correct['daily_demand'] = (weekend_od_correct['total_trips'] / n_weekends).round(2)
    weekend_od_correct['daily_fare'] = (weekend_od_correct['total_fare'] / n_weekends).round(2)
    weekend_od_correct['daily_distance'] = (weekend_od_correct['total_distance'] / n_weekends).round(2)
    weekend_od_correct['daily_passengers'] = (weekend_od_correct['total_passengers'] / n_weekends).round(2)

    # æ·»åŠ æ ‡è¯†
    weekend_od_correct['day_type'] = 'Weekend'
    weekend_od_correct['n_days'] = n_weekends

    print(f"   âœ… å‘¨æœ«ODå¯¹: {len(weekend_od_correct):,} å¯¹")
    print(f"   ğŸ“Š éœ€æ±‚ç»Ÿè®¡ (åŸºäº {n_weekends} ä¸ªå‘¨æœ«æ—¥):")
    print(f"      å¹³å‡æ¯å¤©æ€»éœ€æ±‚: {weekend_od_correct['daily_demand'].sum():.0f} è¡Œç¨‹/å¤©")
    print(f"      å¹³å‡ODå¯¹éœ€æ±‚: {weekend_od_correct['daily_demand'].mean():.2f} è¡Œç¨‹/å¤©")
    print(f"      æœ€é«˜å•ODæ—¥éœ€æ±‚: {weekend_od_correct['daily_demand'].max():.0f} è¡Œç¨‹/å¤©")


    print(f"   ğŸ“Š weekday_od_correct: å·¥ä½œæ—¥é™æ€ODæ•°æ® (å¹³å‡æ¯å¤©éœ€æ±‚, {len(weekday_od_correct):,} å¯¹)")
    print(f"   ğŸ“Š weekend_od_correct: å‘¨æœ«é™æ€ODæ•°æ® (å¹³å‡æ¯å¤©éœ€æ±‚, {len(weekend_od_correct):,} å¯¹)")


    weekday_len_od_data_np = max(len(weekday_od_correct['PULocationID'].unique()), len(weekday_od_correct['DOLocationID'].unique()))
    weekend_len_od_data_np = max(len(weekend_od_correct['PULocationID'].unique()), len(weekend_od_correct['DOLocationID'].unique()))  
    weekday_od_np = np.zeros((weekday_len_od_data_np, weekday_len_od_data_np))
    weekend_od_np = np.zeros((weekend_len_od_data_np, weekend_len_od_data_np))
    print(weekday_od_correct.head())
    for i in range(len(weekday_od_correct)):
        pu_id = weekday_od_correct['PULocationID'].iloc[i]
        do_id = weekday_od_correct['DOLocationID'].iloc[i]
        daily_demand = weekday_od_correct['daily_demand'].iloc[i]
        if pu_id < weekday_len_od_data_np and do_id < weekday_len_od_data_np:
            weekday_od_np[pu_id, do_id] = daily_demand
    for i in range(len(weekend_od_correct)):
        pu_id = weekend_od_correct['PULocationID'].iloc[i]
        do_id = weekend_od_correct['DOLocationID'].iloc[i]
        daily_demand = weekend_od_correct['daily_demand'].iloc[i]
        if pu_id < weekend_len_od_data_np and do_id < weekend_len_od_data_np:
            weekend_od_np[pu_id, do_id] = daily_demand
    print(f"   ğŸ“Š å·¥ä½œæ—¥ODçŸ©é˜µå½¢çŠ¶: {weekday_od_np.shape}")
    print(f"   ğŸ“Š å‘¨æœ«ODçŸ©é˜µå½¢çŠ¶: {weekend_od_np.shape}")
    print("maxdailydemand_weekday:", weekday_od_correct['daily_demand'].max())
    print("maxdailydemand_weekend:", weekend_od_correct['daily_demand'].max())
    weekend_od_correct.to_excel(xlsx_weekend_file, index=False)
    weekday_od_correct.to_excel(xlsx_weekday_file, index=False)
    np.save(weekday_od_np_path, weekday_od_np)
    np.save(weekend_od_np_path, weekend_od_np)
    weekday_distance_np = np.zeros((weekday_len_od_data_np, weekday_len_od_data_np))
    weekend_distance_np = np.zeros((weekend_len_od_data_np, weekend_len_od_data_np))
    weekday_adjacency_np = np.zeros((weekday_len_od_data_np, weekday_len_od_data_np))
    weekend_adjacency_np = np.zeros((weekend_len_od_data_np, weekend_len_od_data_np))
    
    print(f"   ğŸ“ æ­£åœ¨è®¡ç®—è·ç¦»çŸ©é˜µå’Œé‚»æ¥çŸ©é˜µ...")
    distancedata = pd.read_csv("data/nyc_taxi_coordinates.csv")
    npdistance = np.zeros((len(distancedata), len(distancedata)))
    for i in range(len(distancedata)):
        for j in range(len(distancedata)):
            if i != j:
                distance = calculate_distance(distancedata['lat'].iloc[i], distancedata['lon'].iloc[i],
                                            distancedata['lat'].iloc[j], distancedata['lon'].iloc[j])
                npdistance[i, j] = distance
    print("median distance:", np.median(npdistance))
    maxtaxirange = np.max(npdistance) * 0.8
    # è®¡ç®—å·¥ä½œæ—¥è·ç¦»çŸ©é˜µå’Œé‚»æ¥çŸ©é˜µ
    for i in range(weekday_distance_np.shape[0]):
        for j in range(weekday_distance_np.shape[1]):
            if i != j and i < len(distancedata) and j < len(distancedata):
                # è®¡ç®—è·ç¦»å¹¶èµ‹å€¼ç»™çŸ©é˜µçš„ç‰¹å®šä½ç½®
                distance = calculate_distance(distancedata['lat'].iloc[i], distancedata['lon'].iloc[i],
                                            distancedata['lat'].iloc[j], distancedata['lon'].iloc[j])
                weekday_distance_np[i, j] = distance
                
                # æ ¹æ®è·ç¦»è®¾ç½®é‚»æ¥çŸ©é˜µ
                if distance > maxtaxirange:
                    weekday_adjacency_np[i, j] = 0
                else:
                    weekday_adjacency_np[i, j] = 1
            elif i == j:
                weekday_distance_np[i, j] = 0
                weekday_adjacency_np[i, j] = 1  # è‡ªå·±åˆ°è‡ªå·±è®¾ä¸º1
    
    # è®¡ç®—å‘¨æœ«è·ç¦»çŸ©é˜µå’Œé‚»æ¥çŸ©é˜µ
    for i in range(weekend_distance_np.shape[0]):
        for j in range(weekend_distance_np.shape[1]):
            if i != j and i < len(distancedata) and j < len(distancedata):
                # è®¡ç®—è·ç¦»å¹¶èµ‹å€¼ç»™çŸ©é˜µçš„ç‰¹å®šä½ç½®
                distance = calculate_distance(distancedata['lat'].iloc[i], distancedata['lon'].iloc[i],
                                            distancedata['lat'].iloc[j], distancedata['lon'].iloc[j])
                weekend_distance_np[i, j] = distance
                
                # æ ¹æ®è·ç¦»è®¾ç½®é‚»æ¥çŸ©é˜µ
                if distance > maxtaxirange:
                    weekend_adjacency_np[i, j] = 0
                else:
                    weekend_adjacency_np[i, j] = 1
            elif i == j:
                weekend_distance_np[i, j] = 0
                weekend_adjacency_np[i, j] = 1  # è‡ªå·±åˆ°è‡ªå·±è®¾ä¸º1
    np.save("data/npy/static/yellow_sod_weekday_distance_" + str_ym + ".npy", weekday_distance_np)
    np.save("data/npy/static/yellow_sod_weekend_distance_" + str_ym + ".npy", weekend_distance_np)
    np.save("data/npy/static/yellow_sod_weekday_adjacency_" + str_ym + ".npy", weekday_adjacency_np)
    np.save("data/npy/static/yellow_sod_weekend_adjacency_" + str_ym + ".npy", weekend_adjacency_np)
    print(f"ğŸ“‚ å·¥ä½œæ—¥é™æ€ODæ•°æ®å·²ä¿å­˜åˆ°: {xlsx_weekday_file}")
    print(f"ğŸ“‚ å‘¨æœ«é™æ€ODæ•°æ®å·²ä¿å­˜åˆ°: {xlsx_weekend_file}")
    print(f"ğŸ“‚ å·¥ä½œæ—¥ODçŸ©é˜µå·²ä¿å­˜åˆ°: {weekday_od_np_path}")
    print(f"ğŸ“‚ å‘¨æœ«ODçŸ©é˜µå·²ä¿å­˜åˆ°: {weekend_od_np_path}")





if __name__ == "__main__":
    year = 2025
    month = 5
    typedata = 'nyc'
    download_data(year, month, typedata)
    describedata(year, month, typedata)
    df = cleandata(year, month, typedata)
    generatestaticdata(year, month, df)
