"""
æµ‹è¯•å·²ä¿å­˜çš„Checkpointåœ¨æ–°éšæœºç¯å¢ƒä¸‹çš„æ¨ç†æ€§èƒ½
ä¸è¿›è¡Œè®­ç»ƒï¼Œåªè¯„ä¼°å·²è®­ç»ƒæ¨¡å‹çš„è¡¨ç°
"""
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

import numpy as np
import random
import torch
from pathlib import Path
from datetime import datetime
import pandas as pd
import glob
import re

from src.Environment import ChargingIntegratedEnvironment
from src.ValueFunction_pytorch import PyTorchChargingValueFunction


def find_latest_checkpoint(checkpoint_dir, by_time=True):
    """
    è‡ªåŠ¨æ‰¾åˆ°ç›®å½•ä¸‹æœ€æ–°çš„checkpoint
    
    Args:
        checkpoint_dir: checkpointç›®å½•è·¯å¾„
        by_time: True=æŒ‰ä¿®æ”¹æ—¶é—´æ‰¾æœ€æ–°, False=æŒ‰episodeç¼–å·æ‰¾æœ€å¤§
        
    Returns:
        int: æœ€æ–°çš„episodeç¼–å·ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°è¿”å›None
    """
    if not os.path.exists(checkpoint_dir):
        print(f"âŒ Checkpointç›®å½•ä¸å­˜åœ¨: {checkpoint_dir}")
        return None
    
    # æŸ¥æ‰¾æ‰€æœ‰full_state_episode_*.pthæ–‡ä»¶
    pattern = os.path.join(checkpoint_dir, "full_state_episode_*.pth")
    checkpoint_files = glob.glob(pattern)
    
    if not checkpoint_files:
        print(f"âŒ æœªæ‰¾åˆ°checkpointæ–‡ä»¶åœ¨: {checkpoint_dir}")
        return None
    
    if by_time:
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæ‰¾æœ€æ–°çš„
        checkpoint_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
        latest_file = checkpoint_files[0]
        filename = os.path.basename(latest_file)
        match = re.search(r'full_state_episode_(\d+)\.pth', filename)
        if match:
            latest_episode = int(match.group(1))
            modification_time = datetime.fromtimestamp(os.path.getmtime(latest_file))
            print(f"âœ“ æ‰¾åˆ° {len(checkpoint_files)} ä¸ªcheckpoints")
            print(f"  æœ€æ–°ä¿®æ”¹: episode {latest_episode} ({modification_time.strftime('%Y-%m-%d %H:%M:%S')})")
            return latest_episode
    else:
        # æŒ‰episodeç¼–å·æ’åºï¼Œæ‰¾æœ€å¤§çš„
        episodes = []
        for filepath in checkpoint_files:
            filename = os.path.basename(filepath)
            match = re.search(r'full_state_episode_(\d+)\.pth', filename)
            if match:
                episodes.append(int(match.group(1)))
        
        if episodes:
            latest_episode = max(episodes)
            print(f"âœ“ æ‰¾åˆ° {len(episodes)} ä¸ªcheckpointsï¼Œæœ€å¤§episode: {latest_episode}")
            return latest_episode
    
    return None


def set_random_seeds(seed=42):
    """è®¾ç½®æ‰€æœ‰éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
    print(f"âœ“ Random seeds set to {seed}")


def load_checkpoint_for_inference(value_function, checkpoint_path):
    """
    åŠ è½½checkpointç”¨äºæ¨ç†ï¼ˆåªåŠ è½½target_networkæƒé‡ï¼‰
    
    Args:
        value_function: PyTorchChargingValueFunctionå®ä¾‹
        checkpoint_path: checkpointæ–‡ä»¶è·¯å¾„
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸåŠ è½½
    """
    try:
        if not os.path.exists(checkpoint_path):
            print(f"âŒ Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
            return False
        
        print(f"ğŸ“‚ åŠ è½½checkpoint: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=value_function.device)
        
        # åŠ è½½target_networkçš„æƒé‡åˆ°ä¸»ç½‘ç»œï¼ˆç”¨äºæ¨ç†ï¼‰
        if 'target_network_state_dict' in checkpoint:
            value_function.network.load_state_dict(checkpoint['target_network_state_dict'])
            print(f"âœ“ æˆåŠŸåŠ è½½target_networkæƒé‡")
        elif 'network_state_dict' in checkpoint:
            value_function.network.load_state_dict(checkpoint['network_state_dict'])
            print(f"âœ“ æˆåŠŸåŠ è½½networkæƒé‡")
        else:
            print(f"âŒ Checkpointä¸­æ²¡æœ‰æ‰¾åˆ°ç½‘ç»œæƒé‡")
            return False
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        value_function.network.eval()
        
        # æ˜¾ç¤ºcheckpointä¿¡æ¯
        if 'episode' in checkpoint:
            print(f"  - Episode: {checkpoint['episode']}")
        if 'training_step' in checkpoint:
            print(f"  - Training step: {checkpoint['training_step']}")
        if 'buffer_size' in checkpoint:
            print(f"  - Buffer size: {checkpoint['buffer_size']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŠ è½½checkpointå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_checkpoint_inference(
    checkpoint_path_aev,
    checkpoint_path_ev,
    num_episodes=5,
    use_intense_requests=True,
    batch_size=256,
    num_vehicles=10,
    num_ev=5,
    transportation_mode='integrated',
    test_seed=9999,  # ä½¿ç”¨ä¸åŒçš„ç§å­æµ‹è¯•æ³›åŒ–èƒ½åŠ›
    use_heuristic=False  ,
    onlyilp = False
):
    """
    æµ‹è¯•å·²ä¿å­˜çš„checkpointåœ¨æ–°ç¯å¢ƒä¸‹çš„æ¨ç†æ€§èƒ½
    
    Args:
        checkpoint_path_aev: AEVçš„checkpointè·¯å¾„
        checkpoint_path_ev: EVçš„checkpointè·¯å¾„
        num_episodes: æµ‹è¯•episodeæ•°é‡
        test_seed: æµ‹è¯•ç”¨çš„éšæœºæ•°ç§å­ï¼ˆä¸åŒäºè®­ç»ƒæ—¶çš„ç§å­ï¼‰
        use_heuristic: æ˜¯å¦ä½¿ç”¨å¯å‘å¼æ–¹æ³•ï¼ˆTrue=å¯å‘å¼ï¼ŒFalse=Gurobi ILPï¼‰
    """
    assignment_method = "å¯å‘å¼" if use_heuristic else "Gurobi ILP"
    print("=== å¼€å§‹Checkpointæ¨ç†æµ‹è¯• ===")
    print(f"ğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"  - æµ‹è¯•episodes: {num_episodes}")
    print(f"  - æµ‹è¯•ç§å­: {test_seed} (ä¸åŒäºè®­ç»ƒç§å­)")
    print(f"  - è½¦è¾†é…ç½®: {num_vehicles} æ€»è½¦è¾†, {num_ev} EV")
    print(f"  - æ¨¡å¼: {transportation_mode}")
    print(f"  - åˆ†é…æ–¹æ³•: {assignment_method}")
    
    # è®¾ç½®æµ‹è¯•ç”¨çš„éšæœºç§å­
    set_random_seeds(seed=test_seed)
    
    # åˆå§‹åŒ–ç¯å¢ƒ
    num_stations = 4
    env = ChargingIntegratedEnvironment(
        num_vehicles=num_vehicles,
        num_stations=num_stations,
        ev_num_vehicles=num_ev,
        random_seed=test_seed,  # ä½¿ç”¨æµ‹è¯•ç§å­
        use_intense_requests=use_intense_requests
    )
    
    env.adp_value = 1  # ä½¿ç”¨ADP
    env.assignmentgurobi = not use_heuristic  # True=ä½¿ç”¨Gurobi, False=ä½¿ç”¨å¯å‘å¼
    
    if use_heuristic:
        print(f"âœ“ ä½¿ç”¨å¯å‘å¼åˆ†é…æ–¹æ³•ï¼ˆä¸ä½¿ç”¨Gurobiä¼˜åŒ–å™¨ï¼‰")
    else:
        print(f"âœ“ ä½¿ç”¨Gurobi ILPä¼˜åŒ–åˆ†é…")
    
    if not onlyilp:
        value_function = PyTorchChargingValueFunction(
            grid_size=env.grid_size,
            num_vehicles=num_vehicles,
            device='cuda' if torch.cuda.is_available() else 'cpu',
            episode_length=env.episode_length,
            max_requests=10000,
            env=env
        )
        
        value_function_ev = PyTorchChargingValueFunction(
            grid_size=env.grid_size,
            num_vehicles=num_vehicles,
            device='cuda' if torch.cuda.is_available() else 'cpu',
            episode_length=env.episode_length,
            max_requests=10000,
            env=env
        )
        
        # åŠ è½½checkpoint
        print("\nğŸ“¦ åŠ è½½AEV checkpoint...")
        if not load_checkpoint_for_inference(value_function, checkpoint_path_aev):
            print("âŒ æ— æ³•åŠ è½½AEV checkpointï¼Œæµ‹è¯•ç»ˆæ­¢")
            return None, None
        
        print("\nğŸ“¦ åŠ è½½EV checkpoint...")
        if not load_checkpoint_for_inference(value_function_ev, checkpoint_path_ev):
            print("âŒ æ— æ³•åŠ è½½EV checkpointï¼Œæµ‹è¯•ç»ˆæ­¢")
            return None, None
        
        # è®¾ç½®value functionåˆ°ç¯å¢ƒ
        env.set_value_function(value_function)
        env.set_value_function_ev(value_function_ev)
    else:
        value_function = None
        value_function_ev = None
        env.adp_value = 0
    print("\nâœ“ CheckpointåŠ è½½å®Œæˆï¼Œå¼€å§‹æ¨ç†æµ‹è¯•...")
    print(f"âœ“ ä½¿ç”¨è®¾å¤‡: {value_function.device if value_function else 'N/A'}")
    
    # æµ‹è¯•ç»“æœè®°å½•
    results = {
        'episode_rewards': [],
        'episode_detailed_stats': [],
        'charging_events': [],
        'battery_levels': [],
        'environment_stats': [],
        'Idle_average': []
    }
    
    # è¿è¡Œæµ‹è¯•episodes
    for episode in range(num_episodes):
        # ä¸ºæ¯ä¸ªepisodeè®¾ç½®ä¸åŒçš„è¯·æ±‚ç”Ÿæˆç§å­
        episode_seed = test_seed + 1000 + episode
        env.set_request_generation_seed(episode_seed)
        print(f"\n{'='*70}")
        print(f"Episode {episode + 1}/{num_episodes}: è¯·æ±‚ç”Ÿæˆç§å­ = {episode_seed}")
        print(f"{'='*70}")
        
        # Resetç¯å¢ƒ
        states = env.reset()
        episode_reward = 0
        episode_charging_events = []
        Idle_list = []
        
        # è¿è¡Œepisode
        for step in range(env.episode_length):
            current_requests = list(env.active_requests.values())
            
            # ç”ŸæˆåŠ¨ä½œï¼ˆä½¿ç”¨å·²è®­ç»ƒçš„ç½‘ç»œï¼Œä¸è®­ç»ƒï¼‰
            if transportation_mode == 'integrated':
                actions, storeactions, storeactions_ev = env.simulate_motion(
                    agents=[], 
                    current_requests=current_requests, 
                    rebalance=True
                )
            elif transportation_mode == 'evfirst':
                actions, storeactions, storeactions_ev = env.simulate_motion_evfirst(
                    agents=[], 
                    current_requests=current_requests, 
                    rebalance=True
                )
            elif transportation_mode == 'aevfirst':
                actions, storeactions, storeactions_ev = env.simulate_motion_aevfirst(
                    agents=[], 
                    current_requests=current_requests, 
                    rebalance=True
                )
            elif transportation_mode == 'mode_onlyadp':
                actions, storeactions, storeactions_ev = env.simulate_motion(
                    agents=[], 
                    current_requests=current_requests, 
                    rebalance=True
                )
            else:
                actions, storeactions, storeactions_ev = env.simulate_motion(
                    agents=[], 
                    current_requests=current_requests, 
                    rebalance=True
                )
                
                
            # æ‰§è¡ŒåŠ¨ä½œ
            next_states, rewards, dur_rewards, done, info = env.step(
                actions, storeactions, storeactions_ev
            )
            
            episode_reward += sum(rewards.values())
            episode_charging_events.extend(info.get('charging_events', []))
            
            # æ¯50æ­¥è¾“å‡ºç»Ÿè®¡
            if step % 50 == 0:
                stats = env.get_stats()
                active_requests = len(env.active_requests) if hasattr(env, 'active_requests') else 0
                
                # ç»Ÿè®¡è½¦è¾†çŠ¶æ€
                vehicle_status_count = {
                    'charging': 0,
                    'onboard': 0,
                    'to_pickup': 0,
                    'to_charge': 0,
                    'idle_moving': 0,
                    'fully_idle': 0
                }
                
                for vid, v in env.vehicles.items():
                    if v['charging_station'] is not None:
                        status = 'charging'
                    elif v['passenger_onboard'] is not None:
                        status = 'onboard'
                    elif v['assigned_request'] is not None:
                        status = 'to_pickup'
                    elif v.get('charging_target') is not None:
                        status = 'to_charge'
                    elif v.get('idle_target') is not None or v.get('target_location') is not None:
                        status = 'idle_moving'
                    else:
                        status = 'fully_idle'
                    vehicle_status_count[status] += 1
                
                step_reward = sum(rewards.values())
                idle_vehicles = vehicle_status_count['fully_idle']
                Idle_list.append(idle_vehicles)
                
                print(f"  Step {step}: Requests={active_requests}, Reward={step_reward:.2f}")
                print(f"    Status: Charging={vehicle_status_count['charging']}, "
                      f"Onboard={vehicle_status_count['onboard']}, "
                      f"To_pickup={vehicle_status_count['to_pickup']}, "
                      f"Idle={idle_vehicles}")
        
        # Episodeç»“æŸç»Ÿè®¡
        results['episode_rewards'].append(episode_reward)
        results['charging_events'].extend(episode_charging_events)
        results['Idle_average'].append(sum(Idle_list)/len(Idle_list) if Idle_list else 0)
        
        stats = env.get_stats()
        results['environment_stats'].append(stats)
        results['battery_levels'].append(stats['average_battery'])
        
        episode_stats = env.get_episode_stats()
        episode_stats['episode_number'] = episode + 1
        episode_stats['episode_reward'] = episode_reward
        episode_stats['charging_events_count'] = len(episode_charging_events)
        results['episode_detailed_stats'].append(episode_stats)
        
        # è¾“å‡ºepisodeæ€»ç»“
        print(f"\nğŸ“Š Episode {episode + 1} å®Œæˆ:")
        print(f"  æ€»å¥–åŠ±: {episode_reward:.2f}")
        print(f"  è®¢å•ç»Ÿè®¡: æ€»={episode_stats['total_orders']}, "
              f"æ¥å—={episode_stats['accepted_orders']}, "
              f"å®Œæˆ={episode_stats['completed_orders']}, "
              f"æ‹’ç»={episode_stats['rejected_orders']}")
        print(f"  å¹³å‡ç”µé‡: {episode_stats['avg_battery_level']:.2f}")
        print(f"  å¹³å‡ç©ºé—²è½¦è¾†: {results['Idle_average'][-1]:.2f}")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    print("\n" + "="*70)
    print("ä¿å­˜æµ‹è¯•ç»“æœ...")
    results_dir = Path("results/checkpoint_inference")
    results_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    method_suffix = "heuristic" if use_heuristic else "gurobi"
    result_file = results_dir / f"inference_test_{use_intense_requests}_{transportation_mode}_{method_suffix}_seed{test_seed}_{timestamp}.xlsx"
    
    # åˆ›å»ºæ±‡æ€»DataFrame
    summary_data = {
        'Episode': range(1, num_episodes + 1),
        'Total_Reward': results['episode_rewards'],
        'Avg_Idle_Vehicles': results['Idle_average'],
        'Avg_Battery': results['battery_levels'],
    }
    
    for i, stats in enumerate(results['episode_detailed_stats']):
        summary_data.setdefault('Total_Orders', []).append(stats['total_orders'])
        summary_data.setdefault('Accepted_Orders', []).append(stats['accepted_orders'])
        summary_data.setdefault('Completed_Orders', []).append(stats['completed_orders'])
        summary_data.setdefault('Rejected_Orders', []).append(stats['rejected_orders'])
    
    summary_df = pd.DataFrame(summary_data)
    
    with pd.ExcelWriter(result_file, engine='openpyxl') as writer:
        summary_df.to_excel(writer, sheet_name='Summary', index=False)
        
        # è®¡ç®—å¹³å‡å€¼
        avg_data = {
            'Metric': ['Avg_Reward', 'Avg_Idle', 'Avg_Battery', 
                      'Avg_Total_Orders', 'Avg_Accepted', 'Avg_Completed', 'Avg_Rejected'],
            'Value': [
                np.mean(results['episode_rewards']),
                np.mean(results['Idle_average']),
                np.mean(results['battery_levels']),
                np.mean([s['total_orders'] for s in results['episode_detailed_stats']]),
                np.mean([s['accepted_orders'] for s in results['episode_detailed_stats']]),
                np.mean([s['completed_orders'] for s in results['episode_detailed_stats']]),
                np.mean([s['rejected_orders'] for s in results['episode_detailed_stats']])
            ]
        }
        avg_df = pd.DataFrame(avg_data)
        avg_df.to_excel(writer, sheet_name='Averages', index=False)
    
    print(f"âœ“ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    print("\n" + "="*70)
    print("ğŸ“ˆ æµ‹è¯•æ€»ç»“:")
    print(f"  å¹³å‡å¥–åŠ±: {np.mean(results['episode_rewards']):.2f} Â± {np.std(results['episode_rewards']):.2f}")
    print(f"  å¹³å‡ç©ºé—²è½¦è¾†: {np.mean(results['Idle_average']):.2f}")
    print(f"  å¹³å‡ç”µé‡: {np.mean(results['battery_levels']):.2f}")
    print(f"  å¹³å‡è®¢å•å®Œæˆ: {np.mean([s['completed_orders'] for s in results['episode_detailed_stats']]):.2f}")
    print(f"  å¹³å‡æ‹’å•ç‡: {np.mean([s['rejected_orders']/(s['total_orders']+1e-6) for s in results['episode_detailed_stats']])*100:.2f}%")
    print("="*70)
    
    return results, env


def main():
    """ä¸»å‡½æ•°ï¼šé…ç½®å¹¶è¿è¡Œcheckpointæ¨ç†æµ‹è¯•"""
    
    # é…ç½®checkpointè·¯å¾„
    checkpoint_dir = "checkpoints"
    transportation_mode = "integrated"
    num_ev = 3  # ğŸ”§ EVæ•°é‡
    num_vehicles = 6  # ğŸ”§ æ€»è½¦è¾†æ•° = 6 (3 EV + 3 AEV)ï¼Œå¿…é¡»åŒ¹é…è®­ç»ƒæ—¶çš„é…ç½®ï¼
    use_intense_requests = True

    
    # ğŸ†• è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°checkpoint
    # aev_checkpoint_dir = f"{checkpoint_dir}/q_networks_{transportation_mode}_{num_ev}_{use_intense_requests}_aev"
    # ev_checkpoint_dir = f"{checkpoint_dir}/q_networks_{transportation_mode}_{num_ev}_{use_intense_requests}_ev"
    # print("ğŸ” æŸ¥æ‰¾æœ€æ–°çš„checkpointï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´ï¼‰...")
    # latest_episode_aev = find_latest_checkpoint(aev_checkpoint_dir, by_time=True)  # True=æŒ‰ä¿®æ”¹æ—¶é—´
    # latest_episode_ev = find_latest_checkpoint(ev_checkpoint_dir, by_time=True)
    # if latest_episode_aev is None or latest_episode_ev is None:
    #     print("âŒ æ— æ³•æ‰¾åˆ°checkpointï¼Œæµ‹è¯•ç»ˆæ­¢")
    #     return
    # episode = min(latest_episode_aev, latest_episode_ev)
    # print(f"ğŸ“Œ å°†ä½¿ç”¨ episode {episode} çš„checkpoint")
    # checkpoint_path_aev = f"{aev_checkpoint_dir}/full_state_episode_{episode}.pth"
    # checkpoint_path_ev = f"{ev_checkpoint_dir}/full_state_episode_{episode}.pth"
    # if not os.path.exists(checkpoint_path_aev):
    #     print(f"âŒ AEV checkpointä¸å­˜åœ¨: {checkpoint_path_aev}")
    #     return
    # if not os.path.exists(checkpoint_path_ev):
    #     print(f"âŒ EV checkpointä¸å­˜åœ¨: {checkpoint_path_ev}")
    #     return
    # use_heuristic = False  # True=å¯å‘å¼(ä¸ç”¨Gurobi), False=Gurobi ILP
    # assignment_method = "å¯å‘å¼" if use_heuristic else "Gurobi ILP"
    # print(f"\nğŸ“‹ æµ‹è¯•é…ç½®:")
    # modelist = ['integrated', 'evfirst', 'aevfirst']
    # for mode in modelist:
    #     results, env = test_checkpoint_inference(
    #         checkpoint_path_aev=checkpoint_path_aev,
    #         checkpoint_path_ev=checkpoint_path_ev,
    #         num_episodes=50,  # æµ‹è¯•5ä¸ªepisodes
    #         use_intense_requests=use_intense_requests,
    #         batch_size=256,
    #         num_vehicles=num_vehicles,
    #         num_ev=num_ev,
    #         transportation_mode=mode,
    #         test_seed=128,
    #         use_heuristic=use_heuristic  # ä¼ é€’å¯å‘å¼é…ç½®
    #     )
    
    
    
    
    results, env = test_checkpoint_inference(
            checkpoint_path_aev=None,
            checkpoint_path_ev=None,
            num_episodes=50,  # æµ‹è¯•5ä¸ªepisodes
            use_intense_requests=use_intense_requests,
            batch_size=256,
            num_vehicles=num_vehicles,
            num_ev=num_ev,
            transportation_mode="mode_onlyadp_unknown",
            test_seed=128,
            use_heuristic=False,  # ä¼ é€’å¯å‘å¼é…ç½®
            onlyilp = True
        )
    # results, env = test_checkpoint_inference(
    #         checkpoint_path_aev=None,
    #         checkpoint_path_ev=None,
    #         num_episodes=50,  # æµ‹è¯•5ä¸ªepisodes
    #         use_intense_requests=use_intense_requests,
    #         batch_size=256,
    #         num_vehicles=num_vehicles,
    #         num_ev=num_ev,
    #         transportation_mode="mode_heuristic",
    #         test_seed=128,
    #         use_heuristic=True,  # ä¼ é€’å¯å‘å¼é…ç½®
    #         onlyilp = True
    #     )
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    main()
