#!/usr/bin/env python3
"""
æµ‹è¯•Q-valueåˆ†æå·¥å…·
"""

import sys
import os
sys.path.append('src')

def test_q_value_analyzer():
    """æµ‹è¯•Q-valueåˆ†æå™¨"""
    print("ğŸš€ Testing Q-Value Analyzer...")
    
    # å¯¼å…¥åˆ†æå™¨
    try:
        from analyze_q_values import QValueAnalyzer
        analyzer = QValueAnalyzer()
        print("âœ… Q-Value Analyzer imported successfully")
    except Exception as e:
        print(f"âŒ Failed to import analyzer: {e}")
        return False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒæ•°æ®é›†æ–‡ä»¶
    dataset_dir = "results/training_datasets"
    if os.path.exists(dataset_dir):
        dataset_files = [f for f in os.listdir(dataset_dir) if f.endswith(('.pkl', '.json'))]
        print(f"ğŸ“ Found {len(dataset_files)} dataset files")
        
        if dataset_files:
            # åˆ†ææœ€æ–°çš„æ–‡ä»¶
            latest_file = max(dataset_files, key=lambda x: os.path.getctime(os.path.join(dataset_dir, x)))
            file_path = os.path.join(dataset_dir, latest_file)
            print(f"ğŸ“Š Analyzing: {latest_file}")
            
            try:
                df = analyzer.run_analysis_from_file(file_path)
                print("âœ… Analysis completed successfully")
                return True
            except Exception as e:
                print(f"âŒ Analysis failed: {e}")
                return False
        else:
            print("âš ï¸  No dataset files found - run training first to generate data")
    else:
        print("âš ï¸  Dataset directory not found - run training first")
    
    return False

def create_sample_experience_data():
    """åˆ›å»ºç¤ºä¾‹experienceæ•°æ®ç”¨äºæµ‹è¯•"""
    import json
    import os
    from datetime import datetime
    
    print("ğŸ”§ Creating sample experience data for testing...")
    
    # åˆ›å»ºç›®å½•
    os.makedirs("results/training_datasets", exist_ok=True)
    
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    sample_experiences = []
    
    # æ¨¡æ‹ŸQ-valueé—®é¢˜ï¼šassignåŠ¨ä½œå¥–åŠ±æ™®éè¾ƒä½
    for i in range(200):
        # IdleåŠ¨ä½œ - è¾ƒé«˜å¥–åŠ±
        if i % 3 == 0:
            exp = {
                'vehicle_id': i % 5,
                'action_type': 'idle',
                'vehicle_location': i % 100,
                'target_location': i % 100,
                'battery_level': 0.8,
                'current_time': i * 5.0,
                'reward': -0.1 + (0.3 if i % 5 == 0 else 0),  # å¤§å¤šæ•°idleå¥–åŠ±è¾ƒå¥½
                'next_vehicle_location': i % 100,
                'next_battery_level': 0.8,
                'num_requests': 10,
                'request_value': 0.0,
                'is_idle': True
            }
        # AssignåŠ¨ä½œ - è¾ƒä½å¥–åŠ±
        elif i % 3 == 1:
            distance = abs((i % 100) - ((i + 15) % 100))
            exp = {
                'vehicle_id': i % 5,
                'action_type': f'assign_{i % 10}',
                'vehicle_location': i % 100,
                'target_location': (i + 15) % 100,
                'battery_level': 0.7,
                'current_time': i * 5.0,
                'reward': -0.5 - (distance * 0.1),  # è·ç¦»è¶Šè¿œæƒ©ç½šè¶Šå¤§
                'next_vehicle_location': (i + 15) % 100,
                'next_battery_level': 0.6,
                'num_requests': 8,
                'request_value': 5.0 + (i % 10),
                'is_idle': False
            }
        # ChargeåŠ¨ä½œ
        else:
            exp = {
                'vehicle_id': i % 5,
                'action_type': f'charge_{i % 3}',
                'vehicle_location': i % 100,
                'target_location': (i + 5) % 100,
                'battery_level': 0.3,
                'current_time': i * 5.0,
                'reward': -0.2,  # å……ç”µå›ºå®šå°å¹…è´Ÿå¥–åŠ±
                'next_vehicle_location': (i + 5) % 100,
                'next_battery_level': 1.0,
                'num_requests': 12,
                'request_value': 0.0,
                'is_idle': False
            }
        
        sample_experiences.append(exp)
    
    # ä¿å­˜ç¤ºä¾‹æ•°æ®
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    sample_data = {
        'timestamp': timestamp,
        'current_time': 1000.0,
        'dataset_size': len(sample_experiences),
        'experiences': sample_experiences,
        'environment_info': {
            'grid_size': 10,
            'num_vehicles': 5,
            'num_charging_stations': 3
        }
    }
    
    # ä¿å­˜ä¸ºJSON
    json_file = f"results/training_datasets/sample_dataset_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(sample_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Sample data created: {json_file}")
    print(f"ğŸ“Š Contains {len(sample_experiences)} experiences")
    
    return json_file

if __name__ == "__main__":
    print("ğŸ§ª Q-Value Analysis Test Suite")
    print("=" * 40)
    
    # é¦–å…ˆå°è¯•åˆ†æç°æœ‰æ•°æ®
    success = test_q_value_analyzer()
    
    if not success:
        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®è¿›è¡Œæµ‹è¯•
        print("\nğŸ”§ No existing data found, creating sample data...")
        sample_file = create_sample_experience_data()
        
        print("\nğŸš€ Running analysis with sample data...")
        try:
            from analyze_q_values import QValueAnalyzer
            analyzer = QValueAnalyzer()
            df = analyzer.run_analysis_from_file(sample_file)
            print("âœ… Sample data analysis completed!")
        except Exception as e:
            print(f"âŒ Sample analysis failed: {e}")
    
    print("\n" + "=" * 40)
    print("ğŸ Test completed!")