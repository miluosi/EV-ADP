"""
è°ƒè¯•Qå€¼ä¸å¥–åŠ±çŸ›ç›¾é—®é¢˜çš„ä¸“é—¨åˆ†æå·¥å…·
åˆ†æä¸ºä»€ä¹ˆassignå¥–åŠ±é«˜ä½†Qå€¼æœ‰æ—¶ä½äºidle
"""

import pandas as pd
import numpy as np
from collections import deque
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_q_value_contradiction(value_function, recent_experiences_count=500):
    """
    ä¸“é—¨åˆ†æQå€¼ä¸å®é™…å¥–åŠ±çŸ›ç›¾çš„é—®é¢˜
    """
    print("ğŸ” Qå€¼ä¸å¥–åŠ±çŸ›ç›¾åˆ†æ")
    print("=" * 60)
    
    if len(value_function.experience_buffer) < 100:
        print("âŒ ç»éªŒæ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†æ")
        return
    
    # 1. è·å–æœ€è¿‘çš„ç»éªŒæ•°æ®
    experiences = list(value_function.experience_buffer)[-recent_experiences_count:]
    
    # 2. æŒ‰åŠ¨ä½œç±»å‹åˆ†ç»„åˆ†æ
    assign_exps = [exp for exp in experiences if exp['action_type'].startswith('assign')]
    idle_exps = [exp for exp in experiences if exp['action_type'] == 'idle']
    charge_exps = [exp for exp in experiences if exp['action_type'].startswith('charge')]
    
    print(f"ğŸ“Š æœ€è¿‘ {len(experiences)} æ¡ç»éªŒåˆ†æ:")
    print(f"   Assignç»éªŒ: {len(assign_exps)}")
    print(f"   Idleç»éªŒ:   {len(idle_exps)}")
    print(f"   Chargeç»éªŒ: {len(charge_exps)}")
    print()
    
    # 3. å¥–åŠ±ç»Ÿè®¡åˆ†æ
    if assign_exps:
        assign_rewards = [exp['reward'] for exp in assign_exps]
        print(f"ğŸ¯ AssignåŠ¨ä½œå¥–åŠ±åˆ†æ:")
        print(f"   å¹³å‡å¥–åŠ±: {np.mean(assign_rewards):.3f}")
        print(f"   ä¸­ä½å¥–åŠ±: {np.median(assign_rewards):.3f}")
        print(f"   å¥–åŠ±èŒƒå›´: [{np.min(assign_rewards):.3f}, {np.max(assign_rewards):.3f}]")
        print(f"   æ­£å¥–åŠ±æ¯”ä¾‹: {len([r for r in assign_rewards if r > 0]) / len(assign_rewards):.1%}")
        print()
    
    if idle_exps:
        idle_rewards = [exp['reward'] for exp in idle_exps]
        print(f"ğŸ’¤ IdleåŠ¨ä½œå¥–åŠ±åˆ†æ:")
        print(f"   å¹³å‡å¥–åŠ±: {np.mean(idle_rewards):.3f}")
        print(f"   ä¸­ä½å¥–åŠ±: {np.median(idle_rewards):.3f}")
        print(f"   å¥–åŠ±èŒƒå›´: [{np.min(idle_rewards):.3f}, {np.max(idle_rewards):.3f}]")
        print(f"   æ­£å¥–åŠ±æ¯”ä¾‹: {len([r for r in idle_rewards if r > 0]) / len(idle_rewards):.1%}")
        print()
    
    # 4. ç½‘ç»œé¢„æµ‹Qå€¼åˆ†æ
    print("ğŸ§  å½“å‰ç½‘ç»œQå€¼é¢„æµ‹åˆ†æ:")
    try:
        # éšæœºæŠ½å–ä¸€äº›ç»éªŒè¿›è¡ŒQå€¼é¢„æµ‹
        sample_size = min(50, len(experiences))
        sample_exps = np.random.choice(experiences, sample_size, replace=False)
        
        assign_q_values = []
        idle_q_values = []
        actual_assign_rewards = []
        actual_idle_rewards = []
        
        for exp in sample_exps:
            # è·å–Qå€¼é¢„æµ‹
            q_value = value_function.get_q_value(
                vehicle_id=exp['vehicle_id'],
                action_type=exp['action_type'],
                vehicle_location=exp['vehicle_location'],
                target_location=exp['target_location'],
                current_time=exp['current_time'],
                other_vehicles=exp['other_vehicles'],
                num_requests=exp['num_requests'],
                battery_level=exp.get('battery_level', 1.0),
                request_value=exp.get('request_value', 0.0)
            )
            
            if exp['action_type'].startswith('assign'):
                assign_q_values.append(q_value)
                actual_assign_rewards.append(exp['reward'])
            elif exp['action_type'] == 'idle':
                idle_q_values.append(q_value)
                actual_idle_rewards.append(exp['reward'])
        
        if assign_q_values:
            print(f"   Assign Qå€¼: å¹³å‡={np.mean(assign_q_values):.3f}, èŒƒå›´=[{np.min(assign_q_values):.3f}, {np.max(assign_q_values):.3f}]")
            print(f"   å¯¹åº”å®é™…å¥–åŠ±: å¹³å‡={np.mean(actual_assign_rewards):.3f}")
        
        if idle_q_values:
            print(f"   Idle Qå€¼:   å¹³å‡={np.mean(idle_q_values):.3f}, èŒƒå›´=[{np.min(idle_q_values):.3f}, {np.max(idle_q_values):.3f}]")
            print(f"   å¯¹åº”å®é™…å¥–åŠ±: å¹³å‡={np.mean(actual_idle_rewards):.3f}")
        
        # Qå€¼ä¸å¥–åŠ±çš„ç›¸å…³æ€§åˆ†æ
        if assign_q_values and len(assign_q_values) > 3:
            assign_correlation = np.corrcoef(assign_q_values, actual_assign_rewards)[0, 1]
            print(f"   Assign Qå€¼ä¸å¥–åŠ±ç›¸å…³æ€§: {assign_correlation:.3f}")
        
        if idle_q_values and len(idle_q_values) > 3:
            idle_correlation = np.corrcoef(idle_q_values, actual_idle_rewards)[0, 1]
            print(f"   Idle Qå€¼ä¸å¥–åŠ±ç›¸å…³æ€§: {idle_correlation:.3f}")
        
        print()
        
    except Exception as e:
        print(f"   âŒ Qå€¼åˆ†æå¤±è´¥: {e}")
    
    # 5. è®­ç»ƒé‡‡æ ·åˆ†æ
    print("ğŸ² è®­ç»ƒé‡‡æ ·åˆ†æ:")
    try:
        # æ¨¡æ‹Ÿä¸€æ¬¡è®­ç»ƒé‡‡æ ·
        sample_batch = value_function._action_balanced_sample(64)
        sample_assign_count = len([exp for exp in sample_batch if exp['action_type'].startswith('assign')])
        sample_idle_count = len([exp for exp in sample_batch if exp['action_type'] == 'idle'])
        sample_charge_count = len([exp for exp in sample_batch if exp['action_type'].startswith('charge')])
        
        print(f"   æœ€æ–°è®­ç»ƒæ‰¹æ¬¡æ„æˆ: Assign={sample_assign_count}, Idle={sample_idle_count}, Charge={sample_charge_count}")
        
        # åˆ†æè®­ç»ƒæ‰¹æ¬¡ä¸­çš„å¥–åŠ±åˆ†å¸ƒ
        sample_assign_rewards = [exp['reward'] for exp in sample_batch if exp['action_type'].startswith('assign')]
        sample_idle_rewards = [exp['reward'] for exp in sample_batch if exp['action_type'] == 'idle']
        
        if sample_assign_rewards:
            print(f"   è®­ç»ƒæ‰¹æ¬¡Assignå¹³å‡å¥–åŠ±: {np.mean(sample_assign_rewards):.3f}")
        if sample_idle_rewards:
            print(f"   è®­ç»ƒæ‰¹æ¬¡Idleå¹³å‡å¥–åŠ±: {np.mean(sample_idle_rewards):.3f}")
        
    except Exception as e:
        print(f"   âŒ é‡‡æ ·åˆ†æå¤±è´¥: {e}")
    
    print()
    
    # 6. é—®é¢˜è¯Šæ–­å»ºè®®
    print("ğŸ”§ é—®é¢˜è¯Šæ–­ä¸å»ºè®®:")
    
    # æ£€æŸ¥å¥–åŠ±å·®å¼‚
    if assign_exps and idle_exps:
        avg_assign_reward = np.mean([exp['reward'] for exp in assign_exps])
        avg_idle_reward = np.mean([exp['reward'] for exp in idle_exps])
        
        if avg_assign_reward > avg_idle_reward:
            print(f"   âœ… å¥–åŠ±é€»è¾‘æ­£ç¡®: Assign({avg_assign_reward:.2f}) > Idle({avg_idle_reward:.2f})")
            
            # å¦‚æœå¥–åŠ±é€»è¾‘æ­£ç¡®ä½†Qå€¼ä¸å¯¹ï¼Œå¯èƒ½çš„åŸå› ï¼š
            print("   å¯èƒ½çš„Qå€¼çŸ›ç›¾åŸå› :")
            print("   1. ğŸ”„ è®­ç»ƒå°šæœªæ”¶æ•›ï¼Œéœ€è¦æ›´å¤šè®­ç»ƒæ­¥éª¤")
            print("   2. ğŸ“Š æ ·æœ¬ä¸å‡è¡¡ï¼Œidleæ ·æœ¬è¿‡å¤šå½±å“ç½‘ç»œå­¦ä¹ ")
            print("   3. ğŸ¯ ç›®æ ‡Qå€¼è®¡ç®—æœ‰è¯¯ï¼Œæ£€æŸ¥TD targetè®¡ç®—")
            print("   4. ğŸ—ï¸ ç½‘ç»œå®¹é‡ä¸è¶³ï¼Œæ— æ³•å­¦ä¹ å¤æ‚çš„çŠ¶æ€-åŠ¨ä½œæ˜ å°„")
            print("   5. ğŸ“ˆ å­¦ä¹ ç‡è¿‡é«˜æˆ–è¿‡ä½ï¼Œå½±å“æ”¶æ•›")
            
            # å…·ä½“å»ºè®®
            print("\n   ğŸš€ æ”¹è¿›å»ºè®®:")
            print("   1. å¢å¼ºaction-balancedé‡‡æ ·æƒé‡")
            print("   2. è°ƒæ•´å­¦ä¹ ç‡å’Œè®­ç»ƒé¢‘ç‡")
            print("   3. æ·»åŠ assignåŠ¨ä½œçš„é¢å¤–å¥–åŠ±bonus")
            print("   4. å¢åŠ ç½‘ç»œæ·±åº¦æˆ–å®½åº¦")
            print("   5. ä½¿ç”¨prioritized experience replay")
        
        else:
            print(f"   âŒ å¥–åŠ±é€»è¾‘å¼‚å¸¸: Assign({avg_assign_reward:.2f}) <= Idle({avg_idle_reward:.2f})")
            print("   å»ºè®®æ£€æŸ¥å¥–åŠ±å‡½æ•°è®¾è®¡å’Œç¯å¢ƒçŠ¶æ€è½¬æ¢é€»è¾‘")

if __name__ == "__main__":
    print("Qå€¼çŸ›ç›¾åˆ†æå·¥å…·")
    print("ä½¿ç”¨æ–¹æ³•: analyze_q_value_contradiction(value_function)")