#!/usr/bin/env python3
"""
æ›¿æ¢ç°æœ‰ç¥ç»ç½‘ç»œç»“æ„ä»¥å¢å¼ºActionåŒºåˆ†åº¦çš„æ–¹æ¡ˆ
è¿™ä¸ªæ–‡ä»¶åŒ…å«å¯ä»¥ç›´æ¥é›†æˆåˆ°ç°æœ‰ValueFunction_pytorch.pyä¸­çš„æ”¹è¿›
"""

import torch
import torch.nn as nn

class EnhancedPathBasedNetwork(nn.Module):
    """
    å¢å¼ºç‰ˆè·¯å¾„åŸºç¡€ç¥ç»ç½‘ç»œ - å¯ç›´æ¥æ›¿æ¢ç°æœ‰çš„PyTorchPathBasedNetwork
    
    ä¸»è¦æ”¹è¿›ï¼š
    1. æ˜¾å¼çš„Action Type Embedding
    2. å¢å¼ºçš„å»¶è¿Ÿæ¨¡å¼åŒºåˆ†
    3. Action-specificç‰¹å¾å¤„ç†
    4. æ›´å¥½çš„ç‰¹å¾èåˆ
    """
    
    def __init__(self, 
                 num_locations: int,
                 max_capacity: int,
                 embedding_dim: int = 128,
                 lstm_hidden: int = 256,
                 dense_hidden: int = 512,
                 pretrained_embeddings = None):
        super(EnhancedPathBasedNetwork, self).__init__()
        
        self.num_locations = num_locations
        self.max_capacity = max_capacity
        self.embedding_dim = embedding_dim
        
        # 1. Action Type Embedding - æ˜¾å¼åŒºåˆ†ä¸åŒåŠ¨ä½œç±»å‹
        self.action_type_to_id = {
            'assign': 1,
            'charge': 2, 
            'idle': 3,
            'unknown': 0
        }
        self.action_type_embedding = nn.Embedding(
            num_embeddings=4,  # assign, charge, idle, unknown
            embedding_dim=embedding_dim // 4,
            padding_idx=0
        )
        
        # 2. ä½ç½®åµŒå…¥ï¼ˆä¿æŒåŸæœ‰ï¼‰
        self.location_embedding = nn.Embedding(
            num_embeddings=num_locations + 1,
            embedding_dim=embedding_dim,
            padding_idx=0
        )
        
        if pretrained_embeddings is not None:
            self.location_embedding.weight.data.copy_(pretrained_embeddings)
        
        # 3. è·¯å¾„LSTMï¼ˆä¿æŒåŸæœ‰ï¼‰
        self.path_lstm = nn.LSTM(
            input_size=embedding_dim + 1,  # location embedding + delay
            hidden_size=lstm_hidden,
            batch_first=True
        )
        
        # 4. æ—¶é—´åµŒå…¥ï¼ˆä¿æŒåŸæœ‰ï¼‰
        self.time_embedding = nn.Sequential(
            nn.Linear(1, embedding_dim // 2),
            nn.ELU()
        )
        
        # 5. ä¸Šä¸‹æ–‡åµŒå…¥ - å¤„ç†ç¯å¢ƒçŠ¶æ€
        self.context_embedding = nn.Sequential(
            nn.Linear(4, embedding_dim // 4),  # other_agents + num_requests + battery + request_value
            nn.ELU()
        )
        
        # 6. Action-specificç‰¹å¾å¤„ç†
        action_feature_dim = embedding_dim // 4
        self.assign_features = nn.Sequential(
            nn.Linear(action_feature_dim, action_feature_dim),
            nn.ELU(),
            nn.Linear(action_feature_dim, action_feature_dim)
        )
        
        self.charge_features = nn.Sequential(
            nn.Linear(action_feature_dim, action_feature_dim),
            nn.ELU(),
            nn.Linear(action_feature_dim, action_feature_dim)
        )
        
        self.idle_features = nn.Sequential(
            nn.Linear(action_feature_dim, action_feature_dim),
            nn.ELU(),
            nn.Linear(action_feature_dim, action_feature_dim)
        )
        
        # 7. æœ€ç»ˆçŠ¶æ€åµŒå…¥
        # è®¡ç®—æ€»ç‰¹å¾ç»´åº¦: path + time + context + action_specific
        total_feature_dim = lstm_hidden + embedding_dim // 2 + embedding_dim // 4 + action_feature_dim
        
        self.state_embedding = nn.Sequential(
            nn.Linear(total_feature_dim, dense_hidden),
            nn.ELU(),
            nn.Dropout(0.1),
            nn.Linear(dense_hidden, dense_hidden // 2),
            nn.ELU(),
            nn.Dropout(0.1),
            nn.Linear(dense_hidden // 2, 1)
        )
        
        # åˆå§‹åŒ–æƒé‡
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        """åˆå§‹åŒ–ç½‘ç»œæƒé‡"""
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        elif isinstance(module, nn.LSTM):
            for name, param in module.named_parameters():
                if 'weight_ih' in name:
                    torch.nn.init.xavier_uniform_(param.data)
                elif 'weight_hh' in name:
                    torch.nn.init.orthogonal_(param.data)
                elif 'bias' in name:
                    param.data.fill_(0)
    
    def _get_action_type_id(self, action_type_str: str) -> int:
        """ä»action_typeå­—ç¬¦ä¸²è·å–ID"""
        if action_type_str.startswith('assign'):
            return self.action_type_to_id['assign']
        elif action_type_str.startswith('charge'):
            return self.action_type_to_id['charge']
        elif action_type_str == 'idle':
            return self.action_type_to_id['idle']
        else:
            return self.action_type_to_id['unknown']
    
    def forward(self, 
                path_locations: torch.Tensor,
                path_delays: torch.Tensor,
                current_time: torch.Tensor,
                other_agents: torch.Tensor,
                num_requests: torch.Tensor,
                battery_level: torch.Tensor = None,
                request_value: torch.Tensor = None,
                action_type_str: str = None) -> torch.Tensor:
        """
        å¢å¼ºçš„å‰å‘ä¼ æ’­ï¼Œæ”¯æŒaction_typeä¿¡æ¯
        
        æ–°å¢å‚æ•°ï¼š
            action_type_str: Actionç±»å‹å­—ç¬¦ä¸²ï¼Œç”¨äºæ˜¾å¼åŒºåˆ†åŠ¨ä½œç±»å‹
        """
        batch_size = path_locations.size(0)
        
        # 1. è·¯å¾„å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        location_embeds = self.location_embedding(path_locations)
        mask = (path_locations != 0).float().unsqueeze(-1)
        masked_delays = path_delays * mask
        path_input = torch.cat([location_embeds, masked_delays], dim=-1)
        
        lstm_out, (hidden, _) = self.path_lstm(path_input)
        path_representation = hidden[-1]  # [batch_size, lstm_hidden]
        
        # 2. æ—¶é—´å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        time_embed = self.time_embedding(current_time)
        
        # 3. å¤„ç†ç¼ºå¤±å€¼
        if battery_level is None:
            battery_level = torch.ones(current_time.size()).to(current_time.device)
        if request_value is None:
            request_value = torch.zeros(current_time.size()).to(current_time.device)
        
        # 4. ä¸Šä¸‹æ–‡ç‰¹å¾åµŒå…¥
        context_features = torch.cat([
            other_agents, num_requests, battery_level, request_value
        ], dim=1)
        context_embed = self.context_embedding(context_features)
        
        # 5. Action TypeåµŒå…¥å’Œç‰¹å®šå¤„ç†
        if action_type_str is not None:
            action_type_id = self._get_action_type_id(action_type_str)
            action_type_ids = torch.full((batch_size,), action_type_id, dtype=torch.long).to(path_locations.device)
            action_type_embed = self.action_type_embedding(action_type_ids)
            
            # Action-specificç‰¹å¾å¤„ç†
            if action_type_str.startswith('assign'):
                action_specific_features = self.assign_features(action_type_embed)
            elif action_type_str.startswith('charge'):
                action_specific_features = self.charge_features(action_type_embed)
            elif action_type_str == 'idle':
                action_specific_features = self.idle_features(action_type_embed)
            else:
                action_specific_features = action_type_embed  # ç›´æ¥ä½¿ç”¨åµŒå…¥
        else:
            # å¦‚æœæ²¡æœ‰action_typeä¿¡æ¯ï¼Œä½¿ç”¨é›¶å‘é‡
            action_specific_features = torch.zeros(batch_size, self.embedding_dim // 4).to(path_locations.device)
        
        # 6. ç‰¹å¾èåˆ
        combined_features = torch.cat([
            path_representation,      # è·¯å¾„è¡¨ç¤º
            time_embed,              # æ—¶é—´åµŒå…¥
            context_embed,           # ä¸Šä¸‹æ–‡åµŒå…¥
            action_specific_features # Actionç‰¹å®šç‰¹å¾
        ], dim=1)
        
        # 7. æœ€ç»ˆå€¼é¢„æµ‹
        value = self.state_embedding(combined_features)
        
        return value


def create_enhanced_input_preparation_methods():
    """
    åˆ›å»ºå¢å¼ºçš„è¾“å…¥å‡†å¤‡æ–¹æ³•ï¼Œå¯ä»¥é›†æˆåˆ°ç°æœ‰çš„PyTorchChargingValueFunctionä¸­
    """
    
    def _prepare_enhanced_network_input_with_action_type(self, vehicle_location: int, target_location: int, 
                                                        current_time: float, other_vehicles: int, 
                                                        num_requests: int, action_type: str, 
                                                        battery_level: float = 1.0, request_value: float = 0.0):
        """
        å¢å¼ºçš„ç½‘ç»œè¾“å…¥å‡†å¤‡æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜ä¸åŒactionç±»å‹çš„åŒºåˆ†åº¦
        """
        path_locations = torch.zeros(1, 3, dtype=torch.long)
        path_delays = torch.zeros(1, 3, 1, dtype=torch.float32)
        
        # ç¡®ä¿ä½ç½®ç´¢å¼•æœ‰æ•ˆ
        safe_vehicle_location = max(0, min(vehicle_location, self.num_locations - 1))
        safe_target_location = max(0, min(target_location, self.num_locations - 1))
        
        path_locations[0, 0] = safe_vehicle_location + 1
        path_locations[0, 1] = safe_target_location + 1
        path_locations[0, 2] = 0  # End token
        
        # æ˜¾è‘—å¢å¼ºä¸åŒactionç±»å‹çš„å»¶è¿Ÿæ¨¡å¼åŒºåˆ†
        if action_type.startswith('assign'):
            # ASSIGN: åŸºäºè¯·æ±‚ä»·å€¼å’Œç´§æ€¥åº¦çš„å»¶è¿Ÿ
            urgency = max(0.0, (self.episode_length - current_time) / self.episode_length)
            value_factor = min(request_value / 50.0, 1.0)  # å½’ä¸€åŒ–è¯·æ±‚ä»·å€¼
            path_delays[0, 0, 0] = 0.0
            path_delays[0, 1, 0] = 0.1 + urgency * 0.3 + value_factor * 0.2  # 0.1-0.6 èŒƒå›´
            
        elif action_type.startswith('charge'):
            # CHARGE: åŸºäºç”µæ± ç”µé‡çš„å»¶è¿Ÿ
            battery_urgency = max(0.0, (0.3 - battery_level) / 0.3)  # ç”µé‡è¶Šä½è¶Šç´§æ€¥
            path_delays[0, 0, 0] = 0.0
            path_delays[0, 1, 0] = 0.7 + battery_urgency * 0.2  # 0.7-0.9 èŒƒå›´ï¼ˆé«˜å»¶è¿Ÿï¼‰
            
        elif action_type == 'idle':
            # IDLE: å¾ˆå°çš„å›ºå®šå»¶è¿Ÿ
            path_delays[0, 0, 0] = 0.0
            path_delays[0, 1, 0] = 0.01  # å¾ˆå°çš„å›ºå®šå€¼
            
        else:
            # å…¶ä»–æƒ…å†µ: ä¸­ç­‰å»¶è¿Ÿ
            path_delays[0, 0, 0] = 0.0
            path_delays[0, 1, 0] = 0.15
        
        # å½’ä¸€åŒ–å…¶ä»–ç‰¹å¾
        time_tensor = torch.tensor([[current_time / self.episode_length]], dtype=torch.float32)
        others_tensor = torch.tensor([[min(other_vehicles, self.num_vehicles) / self.num_vehicles]], dtype=torch.float32)
        requests_tensor = torch.tensor([[min(num_requests, self.max_requests) / self.max_requests]], dtype=torch.float32)
        battery_tensor = torch.tensor([[battery_level]], dtype=torch.float32)
        value_tensor = torch.tensor([[request_value / 100.0]], dtype=torch.float32)
        
        return {
            'path_locations': path_locations.to(self.device),
            'path_delays': path_delays.to(self.device),
            'current_time': time_tensor.to(self.device),
            'other_agents': others_tensor.to(self.device),
            'num_requests': requests_tensor.to(self.device),
            'battery_level': battery_tensor.to(self.device),
            'request_value': value_tensor.to(self.device),
            'action_type_str': action_type  # ä¼ é€’actionç±»å‹ä¿¡æ¯
        }
    
    def enhanced_get_q_value(self, vehicle_id: int, action_type: str, vehicle_location: int, 
                           target_location: int, current_time: float = 0.0, 
                           other_vehicles: int = 0, num_requests: int = 0, 
                           battery_level: float = 1.0, request_value: float = 0.0) -> float:
        """
        å¢å¼ºçš„Qå€¼è®¡ç®—æ–¹æ³•ï¼Œæ”¯æŒaction_typeä¿¡æ¯ä¼ é€’
        """
        # ä½¿ç”¨å¢å¼ºçš„è¾“å…¥å‡†å¤‡æ–¹æ³•
        inputs = self._prepare_enhanced_network_input_with_action_type(
            vehicle_location, target_location, current_time, 
            other_vehicles, num_requests, action_type, battery_level, request_value
        )
        
        # å‰å‘ä¼ æ’­æ—¶ä¼ é€’action_typeä¿¡æ¯
        self.network.eval()
        with torch.no_grad():
            q_value = self.network(
                path_locations=inputs['path_locations'],
                path_delays=inputs['path_delays'],
                current_time=inputs['current_time'],
                other_agents=inputs['other_agents'],
                num_requests=inputs['num_requests'],
                battery_level=inputs['battery_level'],
                request_value=inputs['request_value'],
                action_type_str=action_type  # æ–°å¢ï¼šä¼ é€’actionç±»å‹
            )
            
            return float(q_value.item())
    
    return _prepare_enhanced_network_input_with_action_type, enhanced_get_q_value


def integration_instructions():
    """
    é›†æˆæŒ‡å¯¼ï¼šå¦‚ä½•å°†å¢å¼ºåŠŸèƒ½é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿä¸­
    """
    instructions = """
    ğŸ“‹ é›†æˆå¢å¼ºActionåŒºåˆ†åº¦çš„æ­¥éª¤ï¼š
    
    1ï¸âƒ£ æ›¿æ¢ç¥ç»ç½‘ç»œç±»ï¼š
       å°†ç°æœ‰çš„ PyTorchPathBasedNetwork æ›¿æ¢ä¸º EnhancedPathBasedNetwork
    
    2ï¸âƒ£ æ›´æ–°ç½‘ç»œå®ä¾‹åŒ–ï¼š
       åœ¨ PyTorchChargingValueFunction.__init__ ä¸­ï¼š
       self.network = EnhancedPathBasedNetwork(...)
       self.target_network = EnhancedPathBasedNetwork(...)
    
    3ï¸âƒ£ æ›´æ–°è¾“å…¥å‡†å¤‡æ–¹æ³•ï¼š
       æ·»åŠ  _prepare_enhanced_network_input_with_action_type æ–¹æ³•
    
    4ï¸âƒ£ æ›´æ–°Qå€¼è®¡ç®—æ–¹æ³•ï¼š
       ä¿®æ”¹ get_q_value æ–¹æ³•ä»¥ä¼ é€’ action_type_str å‚æ•°
    
    5ï¸âƒ£ æ›´æ–°è®­ç»ƒæ–¹æ³•ï¼š
       åœ¨ train_step ä¸­ç¡®ä¿ä¼ é€’ action_type_str ä¿¡æ¯
    
    ğŸ”§ ä¸»è¦æ”¹è¿›ç‰¹æ€§ï¼š
    âœ… æ˜¾å¼çš„Action Type Embedding
    âœ… å¢å¼ºçš„å»¶è¿Ÿæ¨¡å¼åŒºåˆ† (assign: 0.1-0.6, charge: 0.7-0.9, idle: 0.01)
    âœ… Action-specificç‰¹å¾å¤„ç†åˆ†æ”¯
    âœ… æ›´å¥½çš„ä¸Šä¸‹æ–‡ä¿¡æ¯èåˆ
    âœ… ä¿æŒä¸ç°æœ‰æ¥å£çš„å…¼å®¹æ€§
    
    ğŸ“Š é¢„æœŸæ•ˆæœï¼š
    - ä¸åŒactionç±»å‹çš„Qå€¼å°†æœ‰æ›´æ˜æ˜¾çš„åŒºåˆ†
    - ç¥ç»ç½‘ç»œèƒ½å¤Ÿå­¦ä¹ åˆ°action-specificçš„æ¨¡å¼
    - å‡å°‘assign Qå€¼æ€»æ˜¯æœ€ä½çš„é—®é¢˜
    """
    return instructions


if __name__ == "__main__":
    print("ğŸš€ å¢å¼ºActionåŒºåˆ†åº¦çš„ç¥ç»ç½‘ç»œæ”¹è¿›æ–¹æ¡ˆ")
    print("=" * 60)
    
    # æ˜¾ç¤ºé›†æˆæŒ‡å¯¼
    print(integration_instructions())
    
    # æµ‹è¯•ç½‘ç»œç»“æ„
    print("\nğŸ§ª æµ‹è¯•å¢å¼ºç½‘ç»œç»“æ„...")
    
    enhanced_network = EnhancedPathBasedNetwork(
        num_locations=100,
        max_capacity=6,
        embedding_dim=128,
        lstm_hidden=256,
        dense_hidden=512
    )
    
    print(f"âœ… ç½‘ç»œå‚æ•°æ€»æ•°: {sum(p.numel() for p in enhanced_network.parameters())}")
    
    # æ¨¡æ‹Ÿè¾“å…¥æµ‹è¯•
    batch_size = 1
    path_locations = torch.randint(1, 101, (batch_size, 3))
    path_delays = torch.rand(batch_size, 3, 1)
    current_time = torch.rand(batch_size, 1)
    other_agents = torch.rand(batch_size, 1)
    num_requests = torch.rand(batch_size, 1)
    battery_level = torch.rand(batch_size, 1)
    request_value = torch.rand(batch_size, 1)
    
    # æµ‹è¯•ä¸åŒactionç±»å‹
    action_types = ['assign_1', 'charge_0', 'idle']
    
    print(f"\nğŸ“Š æµ‹è¯•ä¸åŒActionç±»å‹çš„è¾“å‡º:")
    for action_type in action_types:
        output = enhanced_network(
            path_locations, path_delays, current_time,
            other_agents, num_requests, battery_level, request_value,
            action_type_str=action_type
        )
        print(f"  {action_type:10s}: {output.item():.6f}")
    
    print(f"\nâœ… å¢å¼ºç½‘ç»œæµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ’¡ ä¸‹ä¸€æ­¥ï¼šå°†è¿™äº›æ”¹è¿›é›†æˆåˆ°ç°æœ‰çš„ValueFunction_pytorch.pyä¸­")
